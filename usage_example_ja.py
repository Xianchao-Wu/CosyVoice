import sys
sys.path.append('third_party/Matcha-TTS')
from cosyvoice.cli.cosyvoice import CosyVoice, CosyVoice2
from cosyvoice.utils.file_utils import load_wav
import torchaudio

cosyvoice = CosyVoice2('pretrained_models/CosyVoice2-0.5B', load_jit=False, load_trt=False, load_vllm=False, fp16=False)

# NOTE if you want to reproduce the results on https://funaudiollm.github.io/cosyvoice2, please add text_frontend=False during inference
# zero_shot usage
prompt_speech_16k = load_wav('./asset/zero_shot_prompt.wav', 16000)

# NOTE inference_zero_shot
#for i, j in enumerate(cosyvoice.inference_zero_shot('é ãé›¢ã‚ŒãŸå‹äººã‹ã‚‰èª•ç”Ÿæ—¥ãƒ—ãƒ¬ã‚¼ãƒ³ãƒˆã‚’ã‚‚ã‚‰ã„ã€æ€ã„ãŒã‘ãªã„é©šãã¨æ·±ã„ç¥ç¦ã§å¿ƒãŒç”˜ã„å–œã³ã§æº€ãŸã•ã‚Œã€ç¬‘é¡”ãŒèŠ±ã®ã‚ˆã†ã«å’²ãã¾ã—ãŸã€‚', 'å¸Œæœ›ä½ ä»¥åèƒ½å¤Ÿåšçš„æ¯”æˆ‘è¿˜å¥½å‘¦ã€‚', prompt_speech_16k, stream=False)):
#    import ipdb; ipdb.set_trace()
#    torchaudio.save('1_ja_zero_shot_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)

#for i, j in enumerate(cosyvoice.inference_zero_shot('ã¨ãŠã ã¯ãªã‚Œ ãŸ ã‚†ã†ã˜ã‚“ ã‹ã‚‰ ãŸã‚“ã˜ã‚‡ã† ã³ ã·ã‚Œãœã‚“ã¨ ã‚’ ã‚‚ã‚‰ã„ ã€ ãŠã‚‚ã„ãŒã‘ãªã„ ãŠã©ã‚ã ã¨ ãµã‹ã„ ã—ã‚…ããµã ã§ ã“ã“ã‚ ãŒ ã‚ã¾ã„ ã‚ˆã‚ã“ã³ ã§ ã¿ãŸã• ã‚Œ ã€ ãˆãŒãŠ ãŒ ã¯ãª ã® ã‚ˆã† ã« ã•ã ã¾ã— ãŸ ã€‚', 'å¸Œæœ›ä½ ä»¥åèƒ½å¤Ÿåšçš„æ¯”æˆ‘è¿˜å¥½å‘¦ã€‚', prompt_speech_16k, stream=False)):
#for i, j in enumerate(cosyvoice.inference_zero_shot('ã¨ãŠã ã¯ãªã‚Œ ãŸ ã‚†ã†ã˜ã‚“ ã‹ã‚‰ ãŸã‚“ã˜ã‚‡ã† ã³ ã·ã‚Œãœã‚“ã¨ ã‚’ ã‚‚ã‚‰ã„ ã€ ãŠã‚‚ã„ãŒã‘ãªã„ ãŠã©ã‚ã ã¨ ãµã‹ã„ ã—ã‚…ããµã ã§ ã“ã“ã‚ ãŒ ã‚ã¾ã„ ã‚ˆã‚ã“ã³ ã§ ã¿ãŸã• ã‚Œ ã€ ãˆãŒãŠ ãŒ ã¯ãª ã® ã‚ˆã† ã« ã•ã ã¾ã— ãŸ ã€‚'.replace(' ', ''), 'å¸Œæœ›ä½ ä»¥åèƒ½å¤Ÿåšçš„æ¯”æˆ‘è¿˜å¥½å‘¦ã€‚', prompt_speech_16k, stream=False)):
for i, j in enumerate(cosyvoice.inference_zero_shot('r i N g o o s a N k o t o o r e N j i o n i j u u g o k i r o g u r a m u k a i m a sh I t a'.replace(' ', ''), 'å¸Œæœ›ä½ ä»¥åèƒ½å¤Ÿåšçš„æ¯”æˆ‘è¿˜å¥½å‘¦ã€‚', prompt_speech_16k, stream=False)):
    #import ipdb; ipdb.set_trace()
    torchaudio.save('1_ja_zimuin_zero_shot_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)

examples = [
    "ç§ã¯2025å¹´10æœˆ3æ—¥ã«æ±äº¬ã¸è¡Œãã¾ã™ã€‚",
    "ä¼šè­°ã¯åˆå¾Œ3æ™‚15åˆ†ã‹ã‚‰å§‹ã¾ã‚Šã¾ã™ã€‚",
    "ã‚Šã‚“ã”ã‚’3å€‹ã¨ã‚ªãƒ¬ãƒ³ã‚¸ã‚’25kgè²·ã„ã¾ã—ãŸã€‚",
    "ä»Šå¹´ã®åˆ©ç›Šç‡ã¯12.5ï¼…ã§ã€å£²ä¸Šã¯3å„„5000ä¸‡å††ã§ã—ãŸã€‚",
    "å¹³æˆ31å¹´4æœˆ30æ—¥ã«é€€ä½ã•ã‚Œã¾ã—ãŸã€‚",
    "ç§ã¯ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã¨ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆã‚’ã‚ˆãä½¿ã„ã¾ã™ã€‚",
    "æ˜æ—¥ã®Meetingã¯Zoomã§13:00ã‹ã‚‰ã§ã™ã€‚",
    "æ¬¡ã®å€™è£œã¯ï¼ˆAï¼‰ç”°ä¸­ã•ã‚“ã€ï¼ˆBï¼‰ä½è—¤ã•ã‚“ã§ã™ã€‚",
    "ã‚„ã£ãŸãƒ¼ãƒ¼ãƒ¼ï¼ï¼ï¼ä»Šæ—¥ã¯ã‚ã£ã¡ã‚ƒæ¥½ã—ã„ã€œã€œã€œ",
    "ä»Šæ—¥ã¯æœ€é«˜ğŸ˜Šâœ¨ 100ç‚¹æº€ç‚¹ï¼",
]
aid=0
for example in examples:
    aid+=1
    for i, j in enumerate(cosyvoice.inference_zero_shot(example.replace(' ', ''), 'å¸Œæœ›ä½ ä»¥åèƒ½å¤Ÿåšçš„æ¯”æˆ‘è¿˜å¥½å‘¦ã€‚', prompt_speech_16k, stream=False)):
        #import ipdb; ipdb.set_trace()
        torchaudio.save('1_ja_hanzi_zero_shot_{}_id{}.wav'.format(i, aid), j['tts_speech'], cosyvoice.sample_rate)


'''
  â†’ å¹³å‡å/ç‰‡å‡å2: ã‚ãŸã—ã‚ã«ã›ã‚“ã«ã˜ã‚…ãƒ¼ã”ã­ã‚“ã˜ã‚…ãƒ¼ãŒã¤ã¿ã£ã‹ã«ã¨ãƒ¼ãã‚‡ãƒ¼ãˆã„ãã¾ã™ã€‚
  â†’ å¹³å‡å/ç‰‡å‡å2: ã‹ã„ãã‚ã”ã”ã•ã‚“ã˜ã˜ã‚…ãƒ¼ã”ãµã‚“ã‹ã‚‰ã¯ã˜ã¾ã‚Šã¾ã™ã€‚
  â†’ å¹³å‡å/ç‰‡å‡å2: ã‚Šã‚“ã”ã‚’ã•ã‚“ã“ã¨ãŠã‚Œã‚“ã˜ã‚’ã«ã˜ã‚…ãƒ¼ã”ãã‚ãã‚‰ã‚€ã‹ã„ã¾ã—ãŸã€‚
  â†’ å¹³å‡å/ç‰‡å‡å2: ã“ã¨ã—ã®ã‚Šãˆãã‚Šã¤ã‚ã˜ã‚…ãƒ¼ã«ãƒ¼ã¦ã‚“ã”ã±ãƒ¼ã›ã‚“ã¨ã§ã€ã†ã‚Šã‚ã’ã‚ã•ã‚“ãŠãã”ã›ã‚“ã¾ã‚“ãˆã‚“ã§ã—ãŸã€‚
  â†’ å¹³å‡å/ç‰‡å‡å2: ã¸ãƒ¼ã›ãƒ¼ã•ã‚“ã˜ã‚…ãƒ¼ã„ã¡ã­ã‚“ã—ãŒã¤ã•ã‚“ã˜ã‚…ãƒ¼ã«ã¡ã«ãŸã„ã„ã•ã‚Œã¾ã—ãŸã€‚
  â†’ å¹³å‡å/ç‰‡å‡å2: ã‚ãŸã—ã‚ã“ã‚“ã´ã‚…ãƒ¼ãŸã¨ã„ã‚“ãŸãƒ¼ã­ã£ã¨ã‚’ã‚ˆãã¤ã‹ã„ã¾ã™ã€‚
  â†’ å¹³å‡å/ç‰‡å‡å2: ã‚ã—ãŸã®ã¿ãƒ¼ã¦ãƒã‚“ãã‚ãšãƒ¼ã‚€ã§ã˜ã‚…ãƒ¼ã•ã‚“ï¼šãœã‚ãœã‚ã‹ã‚‰ã§ã™ã€‚
  â†’ å¹³å‡å/ç‰‡å‡å2: ã¤ãã®ã“ãƒ¼ã»ã‚ï¼ˆï¼¡ï¼‰ãŸãªã‹ã•ã‚“ã€ï¼ˆï¼¢ï¼‰ã•ã¨ãƒ¼ã•ã‚“ã§ã™ã€‚
  â†’ å¹³å‡å/ç‰‡å‡å2: ã‚„ã£ãŸãƒ¼ãƒ¼ãƒ¼ï¼ï¼ï¼ãã‚‡ãƒ¼ã‚ã‚ã£ã¡ã‚ƒãŸã®ã—ã„ã€œã€œã€œ
  â†’ å¹³å‡å/ç‰‡å‡å2: ãã‚‡ãƒ¼ã‚ã•ã„ã“ãƒ¼ğŸ˜Šâœ¨ã€€ã²ã‚ƒãã¦ã‚“ã¾ã‚“ã¦ã‚“ï¼
'''
examples = [
    'ã‚ãŸã—ã‚ã«ã›ã‚“ã«ã˜ã‚…ãƒ¼ã”ã­ã‚“ã˜ã‚…ãƒ¼ãŒã¤ã¿ã£ã‹ã«ã¨ãƒ¼ãã‚‡ãƒ¼ãˆã„ãã¾ã™ã€‚',
    'ã‹ã„ãã‚ã”ã”ã•ã‚“ã˜ã˜ã‚…ãƒ¼ã”ãµã‚“ã‹ã‚‰ã¯ã˜ã¾ã‚Šã¾ã™ã€‚',
    'ã‚Šã‚“ã”ã‚’ã•ã‚“ã“ã¨ãŠã‚Œã‚“ã˜ã‚’ã«ã˜ã‚…ãƒ¼ã”ãã‚ãã‚‰ã‚€ã‹ã„ã¾ã—ãŸã€‚',
    'ã“ã¨ã—ã®ã‚Šãˆãã‚Šã¤ã‚ã˜ã‚…ãƒ¼ã«ãƒ¼ã¦ã‚“ã”ã±ãƒ¼ã›ã‚“ã¨ã§ã€ã†ã‚Šã‚ã’ã‚ã•ã‚“ãŠãã”ã›ã‚“ã¾ã‚“ãˆã‚“ã§ã—ãŸã€‚',
    'ã¸ãƒ¼ã›ãƒ¼ã•ã‚“ã˜ã‚…ãƒ¼ã„ã¡ã­ã‚“ã—ãŒã¤ã•ã‚“ã˜ã‚…ãƒ¼ã«ã¡ã«ãŸã„ã„ã•ã‚Œã¾ã—ãŸã€‚',
    'ã‚ãŸã—ã‚ã“ã‚“ã´ã‚…ãƒ¼ãŸã¨ã„ã‚“ãŸãƒ¼ã­ã£ã¨ã‚’ã‚ˆãã¤ã‹ã„ã¾ã™ã€‚',
    'ã‚ã—ãŸã®ã¿ãƒ¼ã¦ãƒã‚“ãã‚ãšãƒ¼ã‚€ã§ã˜ã‚…ãƒ¼ã•ã‚“ï¼šãœã‚ãœã‚ã‹ã‚‰ã§ã™ã€‚',
    'ã¤ãã®ã“ãƒ¼ã»ã‚ï¼ˆï¼¡ï¼‰ãŸãªã‹ã•ã‚“ã€ï¼ˆï¼¢ï¼‰ã•ã¨ãƒ¼ã•ã‚“ã§ã™ã€‚',
    'ã‚„ã£ãŸãƒ¼ãƒ¼ãƒ¼ï¼ï¼ï¼ãã‚‡ãƒ¼ã‚ã‚ã£ã¡ã‚ƒãŸã®ã—ã„ã€œã€œã€œ',
    'ãã‚‡ãƒ¼ã‚ã•ã„ã“ãƒ¼ğŸ˜Šâœ¨ã€€ã²ã‚ƒãã¦ã‚“ã¾ã‚“ã¦ã‚“ï¼',
]
aid=0
for example in examples:
    aid+=1
    for i, j in enumerate(cosyvoice.inference_zero_shot(example.replace(' ', ''), 'å¸Œæœ›ä½ ä»¥åèƒ½å¤Ÿåšçš„æ¯”æˆ‘è¿˜å¥½å‘¦ã€‚', prompt_speech_16k, stream=False)):
        #import ipdb; ipdb.set_trace()
        torchaudio.save('1_ja_hiragana_zero_shot_{}_id{}.wav'.format(i, aid), j['tts_speech'], cosyvoice.sample_rate)



sys.exit(0)

# NOTE add_zero_shot_spk
# save zero_shot spk for future usage
assert cosyvoice.add_zero_shot_spk('å¸Œæœ›ä½ ä»¥åèƒ½å¤Ÿåšçš„æ¯”æˆ‘è¿˜å¥½å‘¦ã€‚', prompt_speech_16k, 'my_zero_shot_spk') is True # TODO é‡è¦çš„æ˜¯ï¼Œè¿™é‡Œçš„'my_zero_shot_spk'å¯¹åº”çš„speaker embedding vectorä¿¡æ¯ï¼Œæ˜¯ä¹‹å‰çš„reference voiceå¯¹åº”çš„speaker embedding vectoræ‹¿åˆ°çš„.

# NOTE inference_zero_shot
for i, j in enumerate(cosyvoice.inference_zero_shot('æ”¶åˆ°å¥½å‹ä»è¿œæ–¹å¯„æ¥çš„ç”Ÿæ—¥ç¤¼ç‰©ï¼Œé‚£ä»½æ„å¤–çš„æƒŠå–œä¸æ·±æ·±çš„ç¥ç¦è®©æˆ‘å¿ƒä¸­å……æ»¡äº†ç”œèœœçš„å¿«ä¹ï¼Œç¬‘å®¹å¦‚èŠ±å„¿èˆ¬ç»½æ”¾ã€‚', '', '', zero_shot_spk_id='my_zero_shot_spk', stream=False)): # TODO éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œè¿™é‡Œä½¿ç”¨çš„æ˜¯å·²æœ‰çš„speaker vectorï¼Œ"my_zero_shot_spk"ã€‚
    import ipdb; ipdb.set_trace()
    torchaudio.save('2_zero_shot_my_zero_shot_spk{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)
cosyvoice.save_spkinfo()

# NOTE inference_cross_lingual
# fine grained control, for supported control, check cosyvoice/tokenizer/tokenizer.py#L248
for i, j in enumerate(cosyvoice.inference_cross_lingual('åœ¨ä»–è®²è¿°é‚£ä¸ªè’è¯æ•…äº‹çš„è¿‡ç¨‹ä¸­ï¼Œä»–çªç„¶[laughter]åœä¸‹æ¥ï¼Œå› ä¸ºä»–è‡ªå·±ä¹Ÿè¢«é€—ç¬‘äº†[laughter]ã€‚', prompt_speech_16k, stream=False)):
    import ipdb; ipdb.set_trace()
    torchaudio.save('3_fine_grained_control_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)

# NOTE inference_instruct2
# instruct usage
for i, j in enumerate(cosyvoice.inference_instruct2('æ”¶åˆ°å¥½å‹ä»è¿œæ–¹å¯„æ¥çš„ç”Ÿæ—¥ç¤¼ç‰©ï¼Œé‚£ä»½æ„å¤–çš„æƒŠå–œä¸æ·±æ·±çš„ç¥ç¦è®©æˆ‘å¿ƒä¸­å……æ»¡äº†ç”œèœœçš„å¿«ä¹ï¼Œç¬‘å®¹å¦‚èŠ±å„¿èˆ¬ç»½æ”¾ã€‚', 'ç”¨å››å·è¯è¯´è¿™å¥è¯', prompt_speech_16k, stream=False)):
    import ipdb; ipdb.set_trace()
    torchaudio.save('4_instruct_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)

# bistream usage, you can use generator as input, this is useful when using text llm model as input
# NOTE you should still have some basic sentence split logic because llm can not handle arbitrary sentence length
def text_generator():
    yield 'æ”¶åˆ°å¥½å‹ä»è¿œæ–¹å¯„æ¥çš„ç”Ÿæ—¥ç¤¼ç‰©ï¼Œ'
    yield 'é‚£ä»½æ„å¤–çš„æƒŠå–œä¸æ·±æ·±çš„ç¥ç¦'
    yield 'è®©æˆ‘å¿ƒä¸­å……æ»¡äº†ç”œèœœçš„å¿«ä¹ï¼Œ'
    yield 'ç¬‘å®¹å¦‚èŠ±å„¿èˆ¬ç»½æ”¾ã€‚'

# NOTE inference_zero_shot
for i, j in enumerate(cosyvoice.inference_zero_shot(text_generator(), 'å¸Œæœ›ä½ ä»¥åèƒ½å¤Ÿåšçš„æ¯”æˆ‘è¿˜å¥½å‘¦ã€‚', prompt_speech_16k, stream=False)):
    import ipdb; ipdb.set_trace()
    torchaudio.save('5_zero_shot_xiwang_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)

